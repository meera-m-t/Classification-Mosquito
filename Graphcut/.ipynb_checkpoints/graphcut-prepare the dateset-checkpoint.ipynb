{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417a0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30dd1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(original_image):\n",
    "    height, width, _ = original_image.shape\n",
    "    left_margin_proportion = 0.1\n",
    "    right_margin_proportion = 0.1\n",
    "    up_margin_proportion = 0.1\n",
    "    down_margin_proportion = 0.1\n",
    "\n",
    "    boundary_rectangle = (\n",
    "        int(width * left_margin_proportion),\n",
    "        int(height * up_margin_proportion),\n",
    "        int(width * (1 - right_margin_proportion)),\n",
    "        int(height * (1 - down_margin_proportion)),\n",
    "    )\n",
    "    number_of_iterations = 5   \n",
    "    img = original_image.reshape((-1, 3))  \n",
    "    gmm_model = GMM(n_components=2 , covariance_type='tied').fit(img)\n",
    "    gmm_label = gmm_model.predict(img)\n",
    "    binarized_image = gmm_label.reshape(original_image.shape[0],original_image.shape[1])    \n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    mask[:] = cv2.GC_PR_BGD\n",
    "    mask[binarized_image == 1] = cv2.GC_FGD\n",
    "\n",
    "    # Arrays used by the algorithm internally\n",
    "    background_model = np.zeros((1, 65), np.float64)\n",
    "    foreground_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    cv2.grabCut(\n",
    "        original_image,\n",
    "        mask,\n",
    "        boundary_rectangle,\n",
    "        background_model,\n",
    "        foreground_model,\n",
    "        number_of_iterations,\n",
    "        cv2.GC_INIT_WITH_MASK,\n",
    "    )\n",
    "\n",
    "    grabcut_mask = np.where((mask == cv2.GC_PR_BGD) | (mask == cv2.GC_BGD), 0, 1).astype(\n",
    "        \"uint8\"\n",
    "    )\n",
    "    segmented_image = original_image.copy() * grabcut_mask[:, :, np.newaxis]\n",
    "    \n",
    "    return segmented_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4f5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSmallComponents(image, threshold):\n",
    "    #find all your connected components (white blobs in your image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    sizes = stats[1:, -2]\n",
    "#     print(sizes)\n",
    "    nb_components = nb_components - 1\n",
    "    print(nb_components)\n",
    "    img2 = np.zeros((output.shape),dtype = np.uint8)\n",
    "    #for every component in the image, you keep it only if it's above threshold\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= threshold:\n",
    "            img2[output == i + 1] = 255\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71baa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image(mask, image):\n",
    "    masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return cv2.resize(masked,(250,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53448d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original\n",
    "import os\n",
    "import glob\n",
    "path = 'dataset'\n",
    "\n",
    "# configfiles = [os.path.join(dirpath, f)\n",
    "for file in list(glob.glob('*.jpg')):\n",
    "    reader = open(file)\n",
    "    print(file)   \n",
    "    \n",
    "\n",
    "\n",
    "#     original_image = cv2.imread(\"images/13976_front.jpg\")\n",
    "#     seg_img = segmentation(original_image)\n",
    "#     gray = cv2.cvtColor(seg_img, cv2.COLOR_BGR2GRAY) \n",
    "#     thresh = cv2.threshold(gray, 100, 255,cv2.THRESH_BINARY)[1]\n",
    "#     clean_img = removeSmallComponents(gray, 100)\n",
    "#     obj_img = clean_image(clean_img, seg_img)\n",
    "\n",
    "\n",
    "#     black_image = np.zeros((500, 500, 3), dtype = \"uint8\")\n",
    "#     overlay_img1 = np.ones(black_image.shape,np.uint8)*255\n",
    "#     rows,cols,channels = obj_img.shape\n",
    "#     overlay_img1[125:rows+125, 125:cols+125 ] = obj_img\n",
    "#     img2gray = cv2.cvtColor(overlay_img1,cv2.COLOR_BGR2GRAY)\n",
    "#     ret, mask = cv2.threshold(img2gray,220,55,cv2.THRESH_BINARY_INV)\n",
    "#     mask_inv = cv2.bitwise_not(mask)\n",
    "#     temp1 = cv2.bitwise_and(black_image,black_image,mask = mask_inv)\n",
    "#     temp2 = cv2.bitwise_and(overlay_img1,overlay_img1, mask = mask)\n",
    "#     result = cv2.add(temp1,temp2)\n",
    "#     cv2.imwrite(,result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82025478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43bb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
